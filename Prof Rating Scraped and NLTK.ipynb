{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Intro to Data Science Industry Project</h1></center>\n",
    "<h2><center>Columbia University Professor Rating System</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webscraping (IDs 20000 to 20100) [Weida]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:45<00:00,  1.05s/it]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import re\n",
    "from urllib.request import urlopen \n",
    "import pandas as pd\n",
    "from tqdm import tqdm #shows progress\n",
    "\n",
    "df_200_201 = pd.DataFrame(columns=['review_id', 'review_date' ,'review_text', 'agree_score', 'disagree_score',\n",
    "                             'funny_score', 'professor_id', 'professor_name'])\n",
    "for i in tqdm(range(20000, 20100)):\n",
    "    url = 'http://culpa.info/reviews/{}'.format(i)\n",
    "    r = urlopen(url).read() \n",
    "    soup = BeautifulSoup(r, \"lxml\") \n",
    "    # if review doesn't exist, it redirects to home page, maybe use len() to check if we got redirected\n",
    "    if len(soup.text) > 15500:\n",
    "        continue\n",
    "\n",
    "    professor_id = int(soup.find(href=re.compile('(professor)'))['href'][12:])\n",
    "    professor_name = soup.find(href=re.compile('(professor)')).text\n",
    "    review_id = int(soup.find(href=re.compile('(reviews)'))['href'][9:])\n",
    "    review_text = soup.find(class_='review_content').text\n",
    "    review_date = pd.Timestamp(soup.find(class_='date').text.strip())\n",
    "    agree_score = int(re.findall('\\d+', soup.find(class_='agree')['value'])[0])\n",
    "    disagree_score = int(re.findall('\\d+', soup.find(class_='disagree')['value'])[0])\n",
    "    funny_score = int(re.findall('\\d+', soup.find(class_='funny')['value'])[0])\n",
    "\n",
    "    to_append = pd.DataFrame(data=[review_id, review_date, review_text, agree_score, \n",
    "                              disagree_score, funny_score, professor_id, professor_name],\n",
    "                            index=['review_id', 'review_date' ,'review_text', 'agree_score', \n",
    "                              'disagree_score', 'funny_score', 'professor_id', 'professor_name']).T\n",
    "    \n",
    "    df_200_201 = pd.concat([df_200_201, to_append], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check out the scraped data: : First 5 Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_text</th>\n",
       "      <th>agree_score</th>\n",
       "      <th>disagree_score</th>\n",
       "      <th>funny_score</th>\n",
       "      <th>professor_id</th>\n",
       "      <th>professor_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>2007-05-18 00:00:00</td>\n",
       "      <td>\\nComing off a semester of very little work in...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3281</td>\n",
       "      <td>Veneziano Broccia, Lillyrose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>2007-05-18 00:00:00</td>\n",
       "      <td>\\nI had Professor Robbins for a lecture in the...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>744</td>\n",
       "      <td>Robbins, Bruce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20002</td>\n",
       "      <td>2007-05-18 00:00:00</td>\n",
       "      <td>\\nIt's a little hard for me to criticize Profe...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>Sacks, Richard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20003</td>\n",
       "      <td>2007-05-18 00:00:00</td>\n",
       "      <td>\\nThis class was a disaster. Professor Daniel ...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>456</td>\n",
       "      <td>Daniel, Valentine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20004</td>\n",
       "      <td>2007-05-19 00:00:00</td>\n",
       "      <td>\\nLovely class and professor. The class was mo...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2371</td>\n",
       "      <td>Radwan, Noha</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  review_id          review_date  \\\n",
       "0     20000  2007-05-18 00:00:00   \n",
       "1     20001  2007-05-18 00:00:00   \n",
       "2     20002  2007-05-18 00:00:00   \n",
       "3     20003  2007-05-18 00:00:00   \n",
       "4     20004  2007-05-19 00:00:00   \n",
       "\n",
       "                                         review_text agree_score  \\\n",
       "0  \\nComing off a semester of very little work in...           0   \n",
       "1  \\nI had Professor Robbins for a lecture in the...           4   \n",
       "2  \\nIt's a little hard for me to criticize Profe...           5   \n",
       "3  \\nThis class was a disaster. Professor Daniel ...           4   \n",
       "4  \\nLovely class and professor. The class was mo...           3   \n",
       "\n",
       "  disagree_score funny_score professor_id                professor_name  \n",
       "0              0           0         3281  Veneziano Broccia, Lillyrose  \n",
       "1              2           0          744                Robbins, Bruce  \n",
       "2              2           0          115                Sacks, Richard  \n",
       "3              2           0          456            Daniel, Valentine   \n",
       "4              3           0         2371                  Radwan, Noha  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_200_201.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webscraping (IDs 70000 to 80000) [Weida v2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['review_id', 'review_date' ,'review_text', 'agree_score', 'disagree_score',\n",
    "                             'funny_score', 'professor_id', 'professor_name', 'course_id', 'course_name'])\n",
    "for i in tqdm(range(70000, 80000)):\n",
    "    url = 'http://culpa.info/reviews/{}'.format(i)\n",
    "    r = urlopen(url).read() \n",
    "    soup = BeautifulSoup(r, \"lxml\") \n",
    "    # if review doesn't exist, it redirects to home page, maybe use len() to check if we got redirected\n",
    "    if len(soup.text) > 15500:\n",
    "        continue\n",
    "    \n",
    "    professor = soup.find(href=re.compile('(professor)'))\n",
    "    if professor == None:\n",
    "        professor_id = None\n",
    "        professor_name = None\n",
    "    else:\n",
    "        professor_id = professor['href'][12:]\n",
    "        professor_name = professor.text\n",
    "    \n",
    "    courses = soup.find_all(href=re.compile('(courses)'))\n",
    "    if courses == None:\n",
    "        course_id = None\n",
    "        course_name = None\n",
    "    else:\n",
    "        course_id = courses[-(len(courses) - 7)]['href'][9:]\n",
    "        course_name = courses[-(len(courses) - 7)].text\n",
    "\n",
    "    review_id = soup.find(href=re.compile('(reviews)'))['href'][9:]\n",
    "    review_text = soup.find(class_='review_content').text\n",
    "    review_date = pd.Timestamp(soup.find(class_='date').text.strip())\n",
    "    agree_score = re.findall('\\d+', soup.find(class_='agree')['value'])[0]\n",
    "    disagree_score = re.findall('\\d+', soup.find(class_='disagree')['value'])[0]\n",
    "    funny_score = re.findall('\\d+', soup.find(class_='funny')['value'])[0]\n",
    "\n",
    "    to_append = pd.DataFrame(data=[review_id, review_date, review_text, agree_score, \n",
    "                                   disagree_score, funny_score, professor_id, professor_name,\n",
    "                                   course_id, course_name],\n",
    "                            index=['review_id', 'review_date' ,'review_text', 'agree_score', \n",
    "                                   'disagree_score', 'funny_score', 'professor_id', \n",
    "                                   'professor_name', 'course_id', 'course_name']).T\n",
    "    \n",
    "    df = pd.concat([df, to_append], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''from bs4 import BeautifulSoup \n",
    "import re\n",
    "from urllib.request import urlopen \n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "df = pd.DataFrame(columns=['review_id', 'review_date' ,'review_text', 'agree_score', 'disagree_score',\n",
    "                             'funny_score', 'professor_id', 'professor_name'])\n",
    "for i in tqdm(range(70000, 80000)):\n",
    "    url = 'http://culpa.info/reviews/{}'.format(i)\n",
    "    r = urlopen(url).read() \n",
    "    soup = BeautifulSoup(r, \"lxml\") \n",
    "    # if review doesn't exist, it redirects to home page, maybe use len() to check if we got redirected\n",
    "    if len(soup.text) > 15500:\n",
    "        continue\n",
    "\n",
    "    professor_id = soup.find(href=re.compile('(professor)'))['href'][12:]\n",
    "    professor_name = soup.find(href=re.compile('(professor)')).text\n",
    "    review_id = soup.find(href=re.compile('(reviews)'))['href'][9:]\n",
    "    review_text = soup.find(class_='review_content').text\n",
    "    review_date = pd.Timestamp(soup.find(class_='date').text.strip())\n",
    "    agree_score = re.findall('\\d+', soup.find(class_='agree')['value'])[0]\n",
    "    disagree_score = re.findall('\\d+', soup.find(class_='disagree')['value'])[0]\n",
    "    funny_score = re.findall('\\d+', soup.find(class_='funny')['value'])[0]\n",
    "\n",
    "    to_append = pd.DataFrame(data=[review_id, review_date, review_text, agree_score, \n",
    "                              disagree_score, funny_score, professor_id, professor_name],\n",
    "                            index=['review_id', 'review_date' ,'review_text', 'agree_score', \n",
    "                              'disagree_score', 'funny_score', 'professor_id', 'professor_name']).T\n",
    "    \n",
    "    df = pd.concat([df, to_append], ignore_index=True)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.professor_id = df.professor_id.apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webscraping (IDs 20000 to 20200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:33<00:00,  6.01it/s]\n"
     ]
    }
   ],
   "source": [
    "df_200_202 = pd.DataFrame(columns=['review_id', 'review_date' ,'review_text', 'agree_score', 'disagree_score',\n",
    "                             'funny_score', 'professor_id', 'professor_name'])\n",
    "for i in tqdm(range(20000, 20200)):\n",
    "    url = 'http://culpa.info/reviews/{}'.format(i)\n",
    "    r = urlopen(url).read() \n",
    "    soup = BeautifulSoup(r, \"lxml\") \n",
    "    # if review doesn't exist, it redirects to home page, maybe use len() to check if we got redirected\n",
    "    if len(soup.text) > 15500:\n",
    "        continue\n",
    "\n",
    "    professor_id = int(soup.find(href=re.compile('(professor)'))['href'][12:])\n",
    "    professor_name = soup.find(href=re.compile('(professor)')).text\n",
    "    review_id = int(soup.find(href=re.compile('(reviews)'))['href'][9:])\n",
    "    review_text = soup.find(class_='review_content').text\n",
    "    review_date = pd.Timestamp(soup.find(class_='date').text.strip())\n",
    "    agree_score = int(re.findall('\\d+', soup.find(class_='agree')['value'])[0])\n",
    "    disagree_score = int(re.findall('\\d+', soup.find(class_='disagree')['value'])[0])\n",
    "    funny_score = int(re.findall('\\d+', soup.find(class_='funny')['value'])[0])\n",
    "\n",
    "    to_append = pd.DataFrame(data=[review_id, review_date, review_text, agree_score, \n",
    "                              disagree_score, funny_score, professor_id, professor_name],\n",
    "                            index=['review_id', 'review_date' ,'review_text', 'agree_score', \n",
    "                              'disagree_score', 'funny_score', 'professor_id', 'professor_name']).T\n",
    "    \n",
    "    df_200_202 = pd.concat([df_200_202, to_append], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check out the scraped Data: First 5 Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_text</th>\n",
       "      <th>agree_score</th>\n",
       "      <th>disagree_score</th>\n",
       "      <th>funny_score</th>\n",
       "      <th>professor_id</th>\n",
       "      <th>professor_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>2007-05-18 00:00:00</td>\n",
       "      <td>\\nComing off a semester of very little work in...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3281</td>\n",
       "      <td>Veneziano Broccia, Lillyrose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>2007-05-18 00:00:00</td>\n",
       "      <td>\\nI had Professor Robbins for a lecture in the...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>744</td>\n",
       "      <td>Robbins, Bruce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20002</td>\n",
       "      <td>2007-05-18 00:00:00</td>\n",
       "      <td>\\nIt's a little hard for me to criticize Profe...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>Sacks, Richard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20003</td>\n",
       "      <td>2007-05-18 00:00:00</td>\n",
       "      <td>\\nThis class was a disaster. Professor Daniel ...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>456</td>\n",
       "      <td>Daniel, Valentine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20004</td>\n",
       "      <td>2007-05-19 00:00:00</td>\n",
       "      <td>\\nLovely class and professor. The class was mo...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2371</td>\n",
       "      <td>Radwan, Noha</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  review_id          review_date  \\\n",
       "0     20000  2007-05-18 00:00:00   \n",
       "1     20001  2007-05-18 00:00:00   \n",
       "2     20002  2007-05-18 00:00:00   \n",
       "3     20003  2007-05-18 00:00:00   \n",
       "4     20004  2007-05-19 00:00:00   \n",
       "\n",
       "                                         review_text agree_score  \\\n",
       "0  \\nComing off a semester of very little work in...           0   \n",
       "1  \\nI had Professor Robbins for a lecture in the...           4   \n",
       "2  \\nIt's a little hard for me to criticize Profe...           5   \n",
       "3  \\nThis class was a disaster. Professor Daniel ...           4   \n",
       "4  \\nLovely class and professor. The class was mo...           3   \n",
       "\n",
       "  disagree_score funny_score professor_id                professor_name  \n",
       "0              0           0         3281  Veneziano Broccia, Lillyrose  \n",
       "1              2           0          744                Robbins, Bruce  \n",
       "2              2           0          115                Sacks, Richard  \n",
       "3              2           0          456            Daniel, Valentine   \n",
       "4              3           0         2371                  Radwan, Noha  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_200_202.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying Natural Language Toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download() # only need to do this once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pranjalbajaj/anaconda/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take a subset of the data (df_200_202) for NLTK analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subset = df_200_202[:20] # subset of the first 10 reviews\n",
    "reviews = subset['review_text'] # just the review column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 373.21it/s]\n"
     ]
    }
   ],
   "source": [
    "all_pred_sentiments = []\n",
    "\n",
    "for review in tqdm(reviews): # for each review, \n",
    "    pred_sentiment = sid.polarity_scores(review) # calculate the sentiment scores\n",
    "    all_pred_sentiments.append(pred_sentiment) # and append them to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subset = pd.concat([subset, pd.DataFrame(all_pred_sentiments)], axis=1) # add these new columns to our dataframe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_text</th>\n",
       "      <th>agree_score</th>\n",
       "      <th>disagree_score</th>\n",
       "      <th>funny_score</th>\n",
       "      <th>professor_id</th>\n",
       "      <th>professor_name</th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>2007-05-18 00:00:00</td>\n",
       "      <td>\\nComing off a semester of very little work in...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3281</td>\n",
       "      <td>Veneziano Broccia, Lillyrose</td>\n",
       "      <td>0.9949</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>2007-05-18 00:00:00</td>\n",
       "      <td>\\nI had Professor Robbins for a lecture in the...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>744</td>\n",
       "      <td>Robbins, Bruce</td>\n",
       "      <td>0.9966</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20002</td>\n",
       "      <td>2007-05-18 00:00:00</td>\n",
       "      <td>\\nIt's a little hard for me to criticize Profe...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>Sacks, Richard</td>\n",
       "      <td>0.9941</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20003</td>\n",
       "      <td>2007-05-18 00:00:00</td>\n",
       "      <td>\\nThis class was a disaster. Professor Daniel ...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>456</td>\n",
       "      <td>Daniel, Valentine</td>\n",
       "      <td>0.9136</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20004</td>\n",
       "      <td>2007-05-19 00:00:00</td>\n",
       "      <td>\\nLovely class and professor. The class was mo...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2371</td>\n",
       "      <td>Radwan, Noha</td>\n",
       "      <td>0.8764</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  review_id          review_date  \\\n",
       "0     20000  2007-05-18 00:00:00   \n",
       "1     20001  2007-05-18 00:00:00   \n",
       "2     20002  2007-05-18 00:00:00   \n",
       "3     20003  2007-05-18 00:00:00   \n",
       "4     20004  2007-05-19 00:00:00   \n",
       "\n",
       "                                         review_text agree_score  \\\n",
       "0  \\nComing off a semester of very little work in...           0   \n",
       "1  \\nI had Professor Robbins for a lecture in the...           4   \n",
       "2  \\nIt's a little hard for me to criticize Profe...           5   \n",
       "3  \\nThis class was a disaster. Professor Daniel ...           4   \n",
       "4  \\nLovely class and professor. The class was mo...           3   \n",
       "\n",
       "  disagree_score funny_score professor_id                professor_name  \\\n",
       "0              0           0         3281  Veneziano Broccia, Lillyrose   \n",
       "1              2           0          744                Robbins, Bruce   \n",
       "2              2           0          115                Sacks, Richard   \n",
       "3              2           0          456            Daniel, Valentine    \n",
       "4              3           0         2371                  Radwan, Noha   \n",
       "\n",
       "   compound    neg    neu    pos  \n",
       "0    0.9949  0.028  0.781  0.190  \n",
       "1    0.9966  0.033  0.735  0.231  \n",
       "2    0.9941  0.040  0.782  0.177  \n",
       "3    0.9136  0.095  0.754  0.151  \n",
       "4    0.8764  0.015  0.862  0.123  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add weights for Agree/Disagree scores and append *Weighted Scores* to the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formula to calculate weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight = subset.loc[1,'agree_score'] * subset.loc[1,'agree_score'] + subset.loc[1,'disagree_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formula to calculate weights while iterating (Sorry, can't get it to function -- brain dead right now haha :P)\n",
    "#### Can anyone fix this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate a non-NDFrame object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-58a8d6a529f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'agree_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdenominator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mw_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'compound'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;31m#calculate weighted score (w_score)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mweighted_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_score\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#append it to the empty pandas column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0msubset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted_score\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#add to the our dataframe, subset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pranjalbajaj/anaconda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, other, ignore_index, verify_integrity)\u001b[0m\n\u001b[1;32m   4643\u001b[0m             \u001b[0mto_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4644\u001b[0m         return concat(to_concat, ignore_index=ignore_index,\n\u001b[0;32m-> 4645\u001b[0;31m                       verify_integrity=verify_integrity)\n\u001b[0m\u001b[1;32m   4646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4647\u001b[0m     def join(self, other, on=None, how='left', lsuffix='', rsuffix='',\n",
      "\u001b[0;32m/Users/pranjalbajaj/anaconda/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, copy)\u001b[0m\n\u001b[1;32m    204\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                        copy=copy)\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pranjalbajaj/anaconda/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobjs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNDFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot concatenate a non-NDFrame object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0;31m# consolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot concatenate a non-NDFrame object"
     ]
    }
   ],
   "source": [
    "weighted_score = pd.DataFrame({'weighted_score' : []}) #empty pandas column\n",
    "\n",
    "for i in tqdm(range(len(subset.index))): #iterate over length of dataframe (i.e. subset.index)\n",
    "    denominator = subset.loc[i,'agree_score'] + subset.loc[i,'disagree_score']\n",
    "    \n",
    "    if denominator != 0: #to avoid math error \n",
    "        weights = subset.loc[i,'agree_score'] / denominator\n",
    "        w_score = subset.loc[i,'compound'] * weight #calculate weighted score (w_score)\n",
    "        weighted_score.append(w_score) #append it to the empty pandas column\n",
    "\n",
    "subset = pd.concat([subset, weighted_score], ignore_index=True) #add to the our dataframe, subset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
